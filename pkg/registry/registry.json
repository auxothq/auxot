{
  "version": "0.1.0",
  "generated_at": "2026-02-26T22:25:14.486Z",
  "models": [
    {
      "id": "kimi-k2-5-f16",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 2052,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "BF16/Kimi-K2.5-BF16-00001-of-00046.gguf"
    },
    {
      "id": "kimi-k2-5-q3-k-s",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 320.7,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q3_K_S/Kimi-K2.5-Q3_K_S-00001-of-00010.gguf"
    },
    {
      "id": "kimi-k2-5-q4-k-s",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 513,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q4_K_S/Kimi-K2.5-Q4_K_S-00001-of-00013.gguf"
    },
    {
      "id": "kimi-k2-5-q5-k-s",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 641.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q5_K_S/Kimi-K2.5-Q5_K_S-00001-of-00015.gguf"
    },
    {
      "id": "kimi-k2-5-q6-k",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 769.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q6_K/Kimi-K2.5-Q6_K-00001-of-00018.gguf"
    },
    {
      "id": "kimi-k2-5-q8-0",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 1026,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q8_0/Kimi-K2.5-Q8_0-00001-of-00023.gguf"
    },
    {
      "id": "kimi-k2-5-q8-k",
      "model_name": "Kimi-K2.5",
      "huggingface_id": "unsloth/Kimi-K2.5-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 262144,
      "vram_requirements_gb": 1026,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "UD-Q8_K_XL/Kimi-K2.5-UD-Q8_K_XL-00001-of-00025.gguf"
    },
    {
      "id": "kimi-k2-f16",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 2052,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "BF16/Kimi-K2-Instruct-BF16-00001-of-00045.gguf"
    },
    {
      "id": "kimi-k2-q3-k-s",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 320.7,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00001-of-00010.gguf"
    },
    {
      "id": "kimi-k2-q4-k-s",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 513,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00001-of-00013.gguf"
    },
    {
      "id": "kimi-k2-q5-k-s",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 641.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00001-of-00015.gguf"
    },
    {
      "id": "kimi-k2-q6-k",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 769.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q6_K/Kimi-K2-Instruct-Q6_K-00001-of-00018.gguf"
    },
    {
      "id": "kimi-k2-q8-0",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 1026,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q8_0/Kimi-K2-Instruct-Q8_0-00001-of-00023.gguf"
    },
    {
      "id": "kimi-k2-q8-k",
      "model_name": "Kimi-K2",
      "huggingface_id": "unsloth/Kimi-K2-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "1026B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 1026,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00001-of-00025.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-f16",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 1342,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/DeepSeek-V3.1-Terminus-BF16-00001-of-00030.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q3-k-s",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 209.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/DeepSeek-V3.1-Terminus-Q3_K_S-00001-of-00006.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q4-k-s",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 335.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/DeepSeek-V3.1-Terminus-Q4_K_S-00001-of-00008.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q5-k-s",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 419.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/DeepSeek-V3.1-Terminus-Q5_K_S-00001-of-00010.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q6-k",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 503.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/DeepSeek-V3.1-Terminus-Q6_K-00001-of-00012.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q8-0",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/DeepSeek-V3.1-Terminus-Q8_0-00001-of-00015.gguf"
    },
    {
      "id": "deepseek-v3-1-terminus-q8-k",
      "model_name": "DeepSeek-V3.1-Terminus",
      "huggingface_id": "unsloth/DeepSeek-V3.1-Terminus-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/DeepSeek-V3.1-Terminus-UD-Q8_K_XL-00001-of-00017.gguf"
    },
    {
      "id": "deepseek-v3-1-f16",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 1342,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/DeepSeek-V3.1-BF16-00001-of-00030.gguf"
    },
    {
      "id": "deepseek-v3-1-q3-k-s",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 209.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/DeepSeek-V3.1-Q3_K_S-00001-of-00006.gguf"
    },
    {
      "id": "deepseek-v3-1-q4-k-s",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 335.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/DeepSeek-V3.1-Q4_K_S-00001-of-00008.gguf"
    },
    {
      "id": "deepseek-v3-1-q5-k-s",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 419.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/DeepSeek-V3.1-Q5_K_S-00001-of-00010.gguf"
    },
    {
      "id": "deepseek-v3-1-q6-k",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 503.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/DeepSeek-V3.1-Q6_K-00001-of-00012.gguf"
    },
    {
      "id": "deepseek-v3-1-q8-0",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/DeepSeek-V3.1-Q8_0-00001-of-00015.gguf"
    },
    {
      "id": "deepseek-v3-1-q8-k",
      "model_name": "DeepSeek-V3.1",
      "huggingface_id": "unsloth/DeepSeek-V3.1-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/DeepSeek-V3.1-UD-Q8_K_XL-00001-of-00017.gguf"
    },
    {
      "id": "deepseek-r1-0528-f16",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 1342,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "BF16/DeepSeek-R1-0528-BF16-00001-of-00030.gguf"
    },
    {
      "id": "deepseek-r1-0528-q3-k-s",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 209.7,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00001-of-00006.gguf"
    },
    {
      "id": "deepseek-r1-0528-q4-k-s",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 335.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00001-of-00008.gguf"
    },
    {
      "id": "deepseek-r1-0528-q5-k-s",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 419.4,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00001-of-00010.gguf"
    },
    {
      "id": "deepseek-r1-0528-q6-k",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 503.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q6_K/DeepSeek-R1-0528-Q6_K-00001-of-00012.gguf"
    },
    {
      "id": "deepseek-r1-0528-q8-0",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "Q8_0/DeepSeek-R1-0528-Q8_0-00001-of-00015.gguf"
    },
    {
      "id": "deepseek-r1-0528-q8-k",
      "model_name": "DeepSeek-R1-0528",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00001-of-00016.gguf"
    },
    {
      "id": "deepseek-r1-f16",
      "model_name": "DeepSeek-R1",
      "huggingface_id": "unsloth/DeepSeek-R1-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 1342,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-BF16/DeepSeek-R1.BF16-00001-of-00030.gguf"
    },
    {
      "id": "deepseek-r1-q6-k",
      "model_name": "DeepSeek-R1",
      "huggingface_id": "unsloth/DeepSeek-R1-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 503.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Q6_K/DeepSeek-R1-Q6_K-00001-of-00012.gguf"
    },
    {
      "id": "deepseek-r1-q8-0",
      "model_name": "DeepSeek-R1",
      "huggingface_id": "unsloth/DeepSeek-R1-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Q8_0/DeepSeek-R1.Q8_0-00001-of-00015.gguf"
    },
    {
      "id": "deepseek-r1-zero-q8-0",
      "model_name": "DeepSeek-R1-Zero",
      "huggingface_id": "unsloth/DeepSeek-R1-Zero-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "671B",
      "default_context_size": 8192,
      "max_context_size": 163840,
      "vram_requirements_gb": 671,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Zero-Q8_0/DeepSeek-R1-Zero-BF16-256x20B-Q8_0-00001-of-00016.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-f16",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 960,
      "capabilities": [
        "code"
      ],
      "file_name": "BF16/Qwen3-Coder-480B-A35B-Instruct-BF16-00001-of-00021.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q3-k-s",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 150,
      "capabilities": [
        "code"
      ],
      "file_name": "Q3_K_S/Qwen3-Coder-480B-A35B-Instruct-Q3_K_S-00001-of-00005.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q4-k-s",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 240,
      "capabilities": [
        "code"
      ],
      "file_name": "Q4_K_S/Qwen3-Coder-480B-A35B-Instruct-Q4_K_S-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q5-k-s",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 300,
      "capabilities": [
        "code"
      ],
      "file_name": "Q5_K_S/Qwen3-Coder-480B-A35B-Instruct-Q5_K_S-00001-of-00007.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q6-k",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 360,
      "capabilities": [
        "code"
      ],
      "file_name": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00001-of-00009.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q8-0",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 480,
      "capabilities": [
        "code"
      ],
      "file_name": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00001-of-00011.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-q8-k",
      "model_name": "Qwen3-Coder-480B-A35B",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 480,
      "capabilities": [
        "code"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q8_K_XL-00001-of-00012.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-f16",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 960,
      "capabilities": [
        "code"
      ],
      "file_name": "BF16/Qwen3-Coder-480B-A35B-Instruct-1M-BF16-00001-of-00021.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 150,
      "capabilities": [
        "code"
      ],
      "file_name": "Q3_K_S/Qwen3-Coder-480B-A35B-Instruct-1M-Q3_K_S-00001-of-00005.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 240,
      "capabilities": [
        "code"
      ],
      "file_name": "Q4_K_S/Qwen3-Coder-480B-A35B-Instruct-1M-Q4_K_S-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 300,
      "capabilities": [
        "code"
      ],
      "file_name": "Q5_K_S/Qwen3-Coder-480B-A35B-Instruct-1M-Q5_K_S-00001-of-00007.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q6-k",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 360,
      "capabilities": [
        "code"
      ],
      "file_name": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-1M-Q6_K-00001-of-00009.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q8-0",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 480,
      "capabilities": [
        "code"
      ],
      "file_name": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-1M-Q8_0-00001-of-00011.gguf"
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-1m-q8-k",
      "model_name": "Qwen3-Coder-480B-A35B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "480B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 480,
      "capabilities": [
        "code"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-Coder-480B-A35B-Instruct-1M-UD-Q8_K_XL-00001-of-00012.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-f16",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 802,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Llama-4-Maverick-17B-128E-Instruct-BF16-00001-of-00018.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q3-k-s",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 125.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/Llama-4-Maverick-17B-128E-Instruct-Q3_K_S-00001-of-00004.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q4-k-s",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 200.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Llama-4-Maverick-17B-128E-Instruct-Q4_K_S-00001-of-00005.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q5-k-s",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 250.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Llama-4-Maverick-17B-128E-Instruct-Q5_K_S-00001-of-00006.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q6-k",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 300.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Llama-4-Maverick-17B-128E-Instruct-Q6_K-00001-of-00007.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q8-0",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 401,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Llama-4-Maverick-17B-128E-Instruct-Q8_0-00001-of-00009.gguf"
    },
    {
      "id": "llama-4-maverick-17b-128e-q8-k",
      "model_name": "Llama-4-Maverick-17B-128E",
      "huggingface_id": "unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "401B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 401,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Llama-4-Maverick-17B-128E-Instruct-UD-Q8_K_XL-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-f16",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 792,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "BF16/Qwen3.5-397B-A17B-BF16-00001-of-00017.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q3-k-s",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 123.8,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3.5-397B-A17B-Q3_K_S-00001-of-00005.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q4-k-s",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 198,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3.5-397B-A17B-Q4_K_S-00001-of-00006.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q5-k-s",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 247.5,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3.5-397B-A17B-Q5_K_S-00001-of-00007.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q6-k",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 297,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q6_K/Qwen3.5-397B-A17B-Q6_K-00001-of-00008.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q8-0",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 396,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q8_0/Qwen3.5-397B-A17B-Q8_0-00001-of-00010.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-397b-a17b-q8-k",
      "model_name": "Qwen3.5-397B-A17B",
      "huggingface_id": "unsloth/Qwen3.5-397B-A17B-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "396B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 396,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3.5-397B-A17B-UD-Q8_K_XL-00001-of-00011.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-f16",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 470,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-235B-A22B-Thinking-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3-VL-235B-A22B-Thinking-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3-VL-235B-A22B-Thinking-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3-VL-235B-A22B-Thinking-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q6-k",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q6_K/Qwen3-VL-235B-A22B-Thinking-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q8-0",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q8_0/Qwen3-VL-235B-A22B-Thinking-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-q8-k",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-VL-235B-A22B-Thinking-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-f32",
      "model_name": "Qwen3-VL-235B-A22B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 940,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-f16",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 470,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-235B-A22B-Instruct-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q3-k-s",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3-VL-235B-A22B-Instruct-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q4-k-s",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3-VL-235B-A22B-Instruct-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q5-k-s",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3-VL-235B-A22B-Instruct-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q6-k",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q6_K/Qwen3-VL-235B-A22B-Instruct-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q8-0",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q8_0/Qwen3-VL-235B-A22B-Instruct-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-q8-k",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-VL-235B-A22B-Instruct-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-f32",
      "model_name": "Qwen3-VL-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 940,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-f16",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 470,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-235B-A22B-Instruct-1M-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3-VL-235B-A22B-Instruct-1M-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3-VL-235B-A22B-Instruct-1M-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3-VL-235B-A22B-Instruct-1M-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q6_K/Qwen3-VL-235B-A22B-Instruct-1M-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q8_0/Qwen3-VL-235B-A22B-Instruct-1M-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-VL-235B-A22B-Instruct-1M-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-instruct-1m-f32",
      "model_name": "Qwen3-VL-235B-A22B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 940,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-f16",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 470,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-235B-A22B-Thinking-1M-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q3-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3-VL-235B-A22B-Thinking-1M-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3-VL-235B-A22B-Thinking-1M-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3-VL-235B-A22B-Thinking-1M-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q6_K/Qwen3-VL-235B-A22B-Thinking-1M-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "Q8_0/Qwen3-VL-235B-A22B-Thinking-1M-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 235,
      "capabilities": [
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-VL-235B-A22B-Thinking-1M-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-vl-235b-a22b-thinking-1m-f32",
      "model_name": "Qwen3-VL-235B-A22B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-235B-A22B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 940,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-f16",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 470,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-235B-A22B-Thinking-2507-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q3-k-s",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/Qwen3-235B-A22B-Thinking-2507-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q4-k-s",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Qwen3-235B-A22B-Thinking-2507-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q5-k-s",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Qwen3-235B-A22B-Thinking-2507-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q6-k",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Qwen3-235B-A22B-Thinking-2507-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q8-0",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Qwen3-235B-A22B-Thinking-2507-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507-q8-k",
      "model_name": "Qwen3-235B-A22B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-235B-A22B-Thinking-2507-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-f16",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 470,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q3-k-s",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q4-k-s",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q5-k-s",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q6-k",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q8-0",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-q8-k",
      "model_name": "Qwen3-235B-A22B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-f16",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 470,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-235B-A22B-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q3-k-s",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q4-k-s",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q5-k-s",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q6-k",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Qwen3-235B-A22B-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q8-0",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Qwen3-235B-A22B-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-q8-k",
      "model_name": "Qwen3-235B-A22B",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-f16",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 470,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-235B-A22B-128K-BF16-00001-of-00010.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q3-k-s",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 73.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/Qwen3-235B-A22B-128K-Q3_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q4-k-s",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 117.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Qwen3-235B-A22B-128K-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q5-k-s",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 146.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Qwen3-235B-A22B-128K-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q6-k",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 176.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Qwen3-235B-A22B-128K-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q8-0",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Qwen3-235B-A22B-128K-Q8_0-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-235b-a22b-128k-q8-k",
      "model_name": "Qwen3-235B-A22B-128K",
      "huggingface_id": "unsloth/Qwen3-235B-A22B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "235B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 235,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-235B-A22B-128K-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "minimax-m2-1-f16",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 458,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/MiniMax-M2.1-BF16-00001-of-00010.gguf"
    },
    {
      "id": "minimax-m2-1-q3-k-s",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 71.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/MiniMax-M2.1-Q3_K_S-00001-of-00002.gguf"
    },
    {
      "id": "minimax-m2-1-q4-k-s",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 114.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/MiniMax-M2.1-Q4_K_S-00001-of-00003.gguf"
    },
    {
      "id": "minimax-m2-1-q5-k-s",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 143.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/MiniMax-M2.1-Q5_K_S-00001-of-00004.gguf"
    },
    {
      "id": "minimax-m2-1-q6-k",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 171.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/MiniMax-M2.1-Q6_K-00001-of-00004.gguf"
    },
    {
      "id": "minimax-m2-1-q8-0",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 229,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/MiniMax-M2.1-Q8_0-00001-of-00005.gguf"
    },
    {
      "id": "minimax-m2-1-q8-k",
      "model_name": "MiniMax-M2.1",
      "huggingface_id": "unsloth/MiniMax-M2.1-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "229B",
      "default_context_size": 8192,
      "max_context_size": 196608,
      "vram_requirements_gb": 229,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/MiniMax-M2.1-UD-Q8_K_XL-00001-of-00006.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-f16",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 244,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "BF16/Qwen3.5-122B-A10B-BF16-00001-of-00005.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q3-k-s",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 38.2,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q3_K_S/Qwen3.5-122B-A10B-Q3_K_S-00001-of-00003.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q4-k-s",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 61,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q4_K_S/Qwen3.5-122B-A10B-Q4_K_S-00001-of-00003.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q5-k-s",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 76.3,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q5_K_S/Qwen3.5-122B-A10B-Q5_K_S-00001-of-00003.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q6-k",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 91.5,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q6_K/Qwen3.5-122B-A10B-Q6_K-00001-of-00004.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q8-0",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 122,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Q8_0/Qwen3.5-122B-A10B-Q8_0-00001-of-00004.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-122b-a10b-q8-k",
      "model_name": "Qwen3.5-122B-A10B",
      "huggingface_id": "unsloth/Qwen3.5-122B-A10B-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "122B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 122,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3.5-122B-A10B-UD-Q8_K_XL-00001-of-00004.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "gpt-oss-120b-q3-k-s",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 36.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/gpt-oss-120b-Q3_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-q4-k-s",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 58.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/gpt-oss-120b-Q4_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-q5-k-s",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 73.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/gpt-oss-120b-Q5_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-q6-k",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 87.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/gpt-oss-120b-Q6_K-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-q8-0",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 117,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/gpt-oss-120b-Q8_0-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-q8-k",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 117,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/gpt-oss-120b-UD-Q8_K_XL-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-120b-f16",
      "model_name": "gpt-oss-120b",
      "huggingface_id": "unsloth/gpt-oss-120b-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 234,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-120b-F16.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q3-k-s",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 36.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q3_K_S/gpt-oss-safeguard-120b-Q3_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q4-k-s",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 58.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/gpt-oss-safeguard-120b-Q4_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q5-k-s",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 73.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/gpt-oss-safeguard-120b-Q5_K_S-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q6-k",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 87.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/gpt-oss-safeguard-120b-Q6_K-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q8-0",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 117,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/gpt-oss-safeguard-120b-Q8_0-00001-of-00002.gguf"
    },
    {
      "id": "gpt-oss-safeguard-120b-q8-k",
      "model_name": "gpt-oss-safeguard-120b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-120b-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "117B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 117,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/gpt-oss-safeguard-120b-UD-Q8_K_XL-00001-of-00002.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-f16",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 216,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00001-of-00005.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q3-k-s",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 33.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-4-Scout-17B-16E-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q4-k-s",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 54,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q4_K_S/Llama-4-Scout-17B-16E-Instruct-Q4_K_S-00001-of-00002.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q5-k-s",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 67.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q5_K_S/Llama-4-Scout-17B-16E-Instruct-Q5_K_S-00001-of-00002.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q6-k",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 81,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q6_K/Llama-4-Scout-17B-16E-Instruct-Q6_K-00001-of-00002.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q8-0",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 108,
      "capabilities": [
        "chat"
      ],
      "file_name": "Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00001-of-00003.gguf"
    },
    {
      "id": "llama-4-scout-17b-16e-q8-k",
      "model_name": "Llama-4-Scout-17B-16E",
      "huggingface_id": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "108B",
      "default_context_size": 8192,
      "max_context_size": 10485760,
      "vram_requirements_gb": 108,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-coder-next-f16",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 160,
      "capabilities": [
        "code"
      ],
      "file_name": "BF16/Qwen3-Coder-Next-BF16-00001-of-00004.gguf"
    },
    {
      "id": "qwen3-coder-next-q5-k-s",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 50,
      "capabilities": [
        "code"
      ],
      "file_name": "Q5_K_S/Qwen3-Coder-Next-Q5_K_S-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-coder-next-q6-k",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 60,
      "capabilities": [
        "code"
      ],
      "file_name": "Q6_K/Qwen3-Coder-Next-Q6_K-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-coder-next-q8-0",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 80,
      "capabilities": [
        "code"
      ],
      "file_name": "Q8_0/Qwen3-Coder-Next-Q8_0-00001-of-00003.gguf"
    },
    {
      "id": "qwen3-coder-next-q3-k-s",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 25,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-Next-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-coder-next-q4-k-s",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 40,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-Next-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-coder-next-q8-k",
      "model_name": "Qwen3-Coder-Next",
      "huggingface_id": "unsloth/Qwen3-Coder-Next-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "80B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 80,
      "capabilities": [
        "code"
      ],
      "file_name": "UD-Q8_K_XL/Qwen3-Coder-Next-UD-Q8_K_XL-00001-of-00003.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-f16",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 142,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "BF16/DeepSeek-R1-Distill-Llama-70B-BF16-00001-of-00003.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q3-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 22.2,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-70B-Q3_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q4-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 35.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-70B-Q4_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q5-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 44.4,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-70B-Q5_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 53.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-70B-Q6_K/DeepSeek-R1-Distill-Llama-70B-Q6_K-00001-of-00002.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 71,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-70B-Q8_0/DeepSeek-R1-Distill-Llama-70B-Q8_0-00001-of-00002.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-70b-q8-k",
      "model_name": "DeepSeek-R1-Distill-Llama-70B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 71,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "UD-Q8_K_XL/DeepSeek-R1-Distill-Llama-70B-UD-Q8_K_XL-00001-of-00002.gguf"
    },
    {
      "id": "llama-3-3-70b-f16",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 142,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Llama-3.3-70B-Instruct-BF16-00001-of-00003.gguf"
    },
    {
      "id": "llama-3-3-70b-q3-k-s",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 22.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-3.3-70B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "llama-3-3-70b-q4-k-s",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 35.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-3.3-70B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "llama-3-3-70b-q5-k-s",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 44.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-3.3-70B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "llama-3-3-70b-q6-k",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 53.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-3.3-70B-Instruct-Q6_K/Llama-3.3-70B-Instruct-Q6_K-00001-of-00002.gguf"
    },
    {
      "id": "llama-3-3-70b-q8-0",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 71,
      "capabilities": [
        "chat"
      ],
      "file_name": "Llama-3.3-70B-Instruct-Q8_0/Llama-3.3-70B-Instruct-Q8_0-00001-of-00002.gguf"
    },
    {
      "id": "llama-3-3-70b-q8-k",
      "model_name": "Llama-3.3-70B",
      "huggingface_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "71B",
      "default_context_size": 131072,
      "max_context_size": 131072,
      "vram_requirements_gb": 71,
      "capabilities": [
        "chat"
      ],
      "file_name": "UD-Q8_K_XL/Llama-3.3-70B-Instruct-UD-Q8_K_XL-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-f16",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 70,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "BF16/Qwen3.5-35B-A3B-BF16-00001-of-00002.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q3-k-s",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 11,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-Q3_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q4-k-s",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 17.5,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-Q4_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q5-k-s",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 21.9,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-Q5_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q6-k",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 26.3,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-Q6_K.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q8-0",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 35,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-Q8_0.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-35b-a3b-q8-k",
      "model_name": "Qwen3.5-35B-A3B",
      "huggingface_id": "unsloth/Qwen3.5-35B-A3B-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "35B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 35,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-35B-A3B-UD-Q8_K_XL.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-vl-32b-f16",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 66,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-32B-Instruct-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-32b-q3-k-s",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 10.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-q4-k-s",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-q5-k-s",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-q6-k",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-32b-q8-0",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-32b-q8-k",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-32b-f32",
      "model_name": "Qwen3-VL-32B",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 132,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-f16",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 66,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-32B-Thinking-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 10.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q6-k",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q8-0",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-q8-k",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-f32",
      "model_name": "Qwen3-VL-32B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 132,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-f16",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 66,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-32B-Instruct-1M-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 10.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-32b-instruct-1m-f32",
      "model_name": "Qwen3-VL-32B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 132,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-f16",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 66,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-32B-Thinking-1M-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 33,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-32B-Thinking-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-32b-thinking-1m-f32",
      "model_name": "Qwen3-VL-32B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-32B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 132,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-32b-f16",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 66,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-32B-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-32b-q3-k-s",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 10.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-32b-q4-k-s",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-32b-q5-k-s",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-32b-q6-k",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-Q6_K.gguf"
    },
    {
      "id": "qwen3-32b-q8-0",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 33,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-Q8_0.gguf"
    },
    {
      "id": "qwen3-32b-q8-k",
      "model_name": "Qwen3-32B",
      "huggingface_id": "unsloth/Qwen3-32B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 33,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-32b-128k-f16",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 66,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-32B-128K-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-32b-128k-q3-k-s",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 10.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-32b-128k-q4-k-s",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 16.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-32b-128k-q5-k-s",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 20.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-32b-128k-q6-k",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-Q6_K.gguf"
    },
    {
      "id": "qwen3-32b-128k-q8-0",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 33,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-Q8_0.gguf"
    },
    {
      "id": "qwen3-32b-128k-q8-k",
      "model_name": "Qwen3-32B-128K",
      "huggingface_id": "unsloth/Qwen3-32B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 33,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-32B-128K-UD-Q8_K_XL.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-32b-f16",
      "model_name": "DeepSeek-R1-Distill-Qwen-32B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 66,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-32B-F16/DeepSeek-R1-Distill-Qwen-32B-F16-00001-of-00002.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-32b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Qwen-32B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 24.8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-32B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-32b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Qwen-32B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "33B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 33,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-32B-Q8_0.gguf"
    },
    {
      "id": "granite-4-0-h-small-f16",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 64,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/granite-4.0-h-small-BF16-00001-of-00002.gguf"
    },
    {
      "id": "granite-4-0-h-small-q3-k-s",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 10,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-Q3_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-small-q4-k-s",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-Q4_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-small-q5-k-s",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 20,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-Q5_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-small-q6-k",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 24,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-Q6_K.gguf"
    },
    {
      "id": "granite-4-0-h-small-q8-0",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 32,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-Q8_0.gguf"
    },
    {
      "id": "granite-4-0-h-small-q8-k",
      "model_name": "granite-4.0-h-small",
      "huggingface_id": "unsloth/granite-4.0-h-small-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "32B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 32,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-small-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-f16",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 62,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-30B-A3B-Instruct-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q3-k-s",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q4-k-s",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q5-k-s",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q6-k",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q8-0",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-q8-k",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-f32",
      "model_name": "Qwen3-VL-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 124,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-f16",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 62,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-30B-A3B-Thinking-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q6-k",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q8-0",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-q8-k",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-f32",
      "model_name": "Qwen3-VL-30B-A3B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 124,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-f16",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 62,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-30B-A3B-Instruct-1M-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-1m-f32",
      "model_name": "Qwen3-VL-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 124,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-f16",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 62,
      "capabilities": [
        "vision"
      ],
      "file_name": "BF16/Qwen3-VL-30B-A3B-Thinking-1M-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q3-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 31,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-30B-A3B-Thinking-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-30b-a3b-thinking-1m-f32",
      "model_name": "Qwen3-VL-30B-A3B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 124,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-f16",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 62,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-30B-A3B-Instruct-2507-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q3-k-s",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q4-k-s",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q5-k-s",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q6-k",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-Q6_K.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q8-0",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-Q8_0.gguf"
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-q8-k",
      "model_name": "Qwen3-30B-A3B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Instruct-2507-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-30b-a3b-f16",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 62,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-30B-A3B-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q3-k-s",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q4-k-s",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q5-k-s",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q6-k",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Q6_K.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q8-0",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Q8_0.gguf"
    },
    {
      "id": "qwen3-30b-a3b-q8-k",
      "model_name": "Qwen3-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-f16",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 62,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-30B-A3B-128K-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q3-k-s",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q4-k-s",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q5-k-s",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q6-k",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-Q6_K.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q8-0",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-Q8_0.gguf"
    },
    {
      "id": "qwen3-30b-a3b-128k-q8-k",
      "model_name": "Qwen3-30B-A3B-128K",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-128K-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-f16",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 62,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/Qwen3-30B-A3B-Thinking-2507-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q3-k-s",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q4-k-s",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q5-k-s",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q6-k",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-Q6_K.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q8-0",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-Q8_0.gguf"
    },
    {
      "id": "qwen3-30b-a3b-thinking-2507-q8-k",
      "model_name": "Qwen3-30B-A3B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-30B-A3B-Thinking-2507-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-f16",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 62,
      "capabilities": [
        "code"
      ],
      "file_name": "BF16/Qwen3-Coder-30B-A3B-Instruct-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q3-k-s",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q4-k-s",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q5-k-s",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q6-k",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q8-0",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-q8-k",
      "model_name": "Qwen3-Coder-30B-A3B",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 31,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-f16",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 62,
      "capabilities": [
        "code"
      ],
      "file_name": "BF16/Qwen3-Coder-30B-A3B-Instruct-1M-BF16-00001-of-00002.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 9.7,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 15.5,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 19.4,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q6-k",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 23.3,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q8-0",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 31,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-1m-q8-k",
      "model_name": "Qwen3-Coder-30B-A3B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "MoE",
      "parameters": "31B",
      "default_context_size": 32768,
      "max_context_size": 1048576,
      "vram_requirements_gb": 31,
      "capabilities": [
        "code"
      ],
      "file_name": "Qwen3-Coder-30B-A3B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-f16",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 54,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/gemma-3-27b-it-qat-BF16-00001-of-00002.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-q3-k-s",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-qat-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-q4-k-s",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 13.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-qat-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-q5-k-s",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-qat-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-q6-k",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 20.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-qat-Q6_K.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-q8-k",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 27,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-qat-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-27b-it-qat-f32",
      "model_name": "gemma-3-27b-it-qat",
      "huggingface_id": "unsloth/gemma-3-27b-it-qat-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 108,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3-27b-it-f16",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 54,
      "capabilities": [
        "chat"
      ],
      "file_name": "BF16/gemma-3-27b-it-BF16-00001-of-00002.gguf"
    },
    {
      "id": "gemma-3-27b-it-q3-k-s",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-q4-k-s",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 13.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-q5-k-s",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-27b-it-q6-k",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 20.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3-27b-it-q8-0",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 27,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3-27b-it-q8-k",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 27,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-27b-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-27b-it-f32",
      "model_name": "gemma-3-27b-it",
      "huggingface_id": "unsloth/gemma-3-27b-it-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 108,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-5-27b-f16",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 54,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "BF16/Qwen3.5-27B-BF16-00001-of-00002.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q3-k-s",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8.5,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-Q3_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q4-k-s",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 13.5,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-Q4_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q5-k-s",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16.9,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-Q5_K_S.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q6-k",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 20.3,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-Q6_K.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q8-0",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 27,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-Q8_0.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "qwen3-5-27b-q8-k",
      "model_name": "Qwen3.5-27B",
      "huggingface_id": "unsloth/Qwen3.5-27B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "27B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 27,
      "capabilities": [
        "chat",
        "vision"
      ],
      "file_name": "Qwen3.5-27B-UD-Q8_K_XL.gguf",
      "mmproj_file_name": "mmproj-F16.gguf"
    },
    {
      "id": "gpt-oss-20b-f16",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 42,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-F16.gguf"
    },
    {
      "id": "gpt-oss-20b-q3-k-s",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 6.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-Q3_K_S.gguf"
    },
    {
      "id": "gpt-oss-20b-q4-k-s",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 10.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-Q4_K_S.gguf"
    },
    {
      "id": "gpt-oss-20b-q5-k-s",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 13.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-Q5_K_S.gguf"
    },
    {
      "id": "gpt-oss-20b-q6-k",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 15.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-Q6_K.gguf"
    },
    {
      "id": "gpt-oss-20b-q8-0",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 21,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-Q8_0.gguf"
    },
    {
      "id": "gpt-oss-20b-q8-k",
      "model_name": "gpt-oss-20b",
      "huggingface_id": "unsloth/gpt-oss-20b-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 21,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-20b-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-f16",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 42,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-F16.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q3-k-s",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 6.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-Q3_K_S.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q4-k-s",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 10.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-Q4_K_S.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q5-k-s",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 13.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-Q5_K_S.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q6-k",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 15.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-Q6_K.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q8-0",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 21,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-Q8_0.gguf"
    },
    {
      "id": "gpt-oss-safeguard-20b-q8-k",
      "model_name": "gpt-oss-safeguard-20b",
      "huggingface_id": "unsloth/gpt-oss-safeguard-20b-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "21B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 21,
      "capabilities": [
        "chat"
      ],
      "file_name": "gpt-oss-safeguard-20b-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-14b-f16",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 30,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-BF16.gguf"
    },
    {
      "id": "qwen3-14b-q3-k-s",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 4.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-14b-q4-k-s",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 7.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-14b-q5-k-s",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 9.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-14b-q6-k",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 11.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-Q6_K.gguf"
    },
    {
      "id": "qwen3-14b-q8-0",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 15,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-Q8_0.gguf"
    },
    {
      "id": "qwen3-14b-q8-k",
      "model_name": "Qwen3-14B",
      "huggingface_id": "unsloth/Qwen3-14B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 15,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-14b-128k-f16",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 30,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-BF16.gguf"
    },
    {
      "id": "qwen3-14b-128k-q3-k-s",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-14b-128k-q4-k-s",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 7.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-14b-128k-q5-k-s",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 9.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-14b-128k-q6-k",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 11.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-Q6_K.gguf"
    },
    {
      "id": "qwen3-14b-128k-q8-0",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 15,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-Q8_0.gguf"
    },
    {
      "id": "qwen3-14b-128k-q8-k",
      "model_name": "Qwen3-14B-128K",
      "huggingface_id": "unsloth/Qwen3-14B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 15,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-14B-128K-UD-Q8_K_XL.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-14b-f16",
      "model_name": "DeepSeek-R1-Distill-Qwen-14B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 30,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-14B-F16.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-14b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Qwen-14B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 11.3,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-14B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-14b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Qwen-14B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "15B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 15,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-14B-Q8_0.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-f16",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 28,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q3-k-s",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 4.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q4-k-s",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q5-k-s",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q6-k",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 10.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q8-0",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-q8-k",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Instruct-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-14b-instruct-2512-f32",
      "model_name": "Ministral-3-14B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Instruct-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 56,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-f16",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 28,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q3-k-s",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 4.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q4-k-s",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q5-k-s",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q6-k",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 10.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q8-0",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-q8-k",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-14B-Reasoning-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-14b-reasoning-2512-f32",
      "model_name": "Ministral-3-14B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-14B-Reasoning-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "14B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 56,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "flux1-schnell-q4-k-s",
      "model_name": "FLUX.1-schnell",
      "huggingface_id": "unsloth/FLUX.1-schnell-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 4096,
      "max_context_size": 4096,
      "vram_requirements_gb": 7,
      "capabilities": [
        "image_generation"
      ],
      "file_name": "flux1-schnell-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-f16",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 24,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-BF16.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q3-k-s",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 3.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q4-k-s",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q5-k-s",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 7.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q6-k",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 9,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-Q6_K.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q8-0",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-Q8_0.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-q8-k",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-f32",
      "model_name": "gemma-3-12b-it-qat",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 48,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-int4-f16",
      "model_name": "gemma-3-12b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-int4-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 24,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-int4-BF16.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-int4-q6-k",
      "model_name": "gemma-3-12b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-int4-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 9,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-int4-Q6_K.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-int4-q8-0",
      "model_name": "gemma-3-12b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-int4-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-qat-int4-Q8_0.gguf"
    },
    {
      "id": "gemma-3-12b-it-qat-int4-f32",
      "model_name": "gemma-3-12b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-12b-it-qat-int4-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 48,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3-12b-it-f16",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 24,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-BF16.gguf"
    },
    {
      "id": "gemma-3-12b-it-q3-k-s",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 3.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-q4-k-s",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-q5-k-s",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 7.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-12b-it-q6-k",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 9,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3-12b-it-q8-0",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3-12b-it-q8-k",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-12b-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-12b-it-f32",
      "model_name": "gemma-3-12b-it",
      "huggingface_id": "unsloth/gemma-3-12b-it-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "12B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 48,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "flux-2-klein-9b-q4-k-s",
      "model_name": "FLUX.2-klein-9B",
      "huggingface_id": "unsloth/FLUX.2-klein-9B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "9B",
      "default_context_size": 4096,
      "max_context_size": 4096,
      "vram_requirements_gb": 8,
      "capabilities": [
        "image_generation"
      ],
      "file_name": "flux-2-klein-9b-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-f16",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-BF16.gguf"
    },
    {
      "id": "qwen3-vl-8b-q3-k-s",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-q4-k-s",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-q5-k-s",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-q6-k",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-8b-q8-0",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-8b-q8-k",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-8b-f32",
      "model_name": "Qwen3-VL-8B",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 32,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-f16",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-BF16.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q6-k",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q8-0",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-q8-k",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-f32",
      "model_name": "Qwen3-VL-8B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 32,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-f16",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q3-k-s",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 6,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Thinking-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-8b-thinking-1m-f32",
      "model_name": "Qwen3-VL-8B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 32,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-f16",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 6,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-8B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-8b-instruct-1m-f32",
      "model_name": "Qwen3-VL-8B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-8B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 32,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-8b-f16",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-BF16.gguf"
    },
    {
      "id": "qwen3-8b-q3-k-s",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-8b-q4-k-s",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-8b-q5-k-s",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-8b-q6-k",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-Q6_K.gguf"
    },
    {
      "id": "qwen3-8b-q8-0",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-Q8_0.gguf"
    },
    {
      "id": "qwen3-8b-q8-k",
      "model_name": "Qwen3-8B",
      "huggingface_id": "unsloth/Qwen3-8B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-8b-128k-f16",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-BF16.gguf"
    },
    {
      "id": "qwen3-8b-128k-q3-k-s",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-8b-128k-q4-k-s",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-8b-128k-q5-k-s",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-8b-128k-q6-k",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-Q6_K.gguf"
    },
    {
      "id": "qwen3-8b-128k-q8-0",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-Q8_0.gguf"
    },
    {
      "id": "qwen3-8b-128k-q8-k",
      "model_name": "Qwen3-8B-128K",
      "huggingface_id": "unsloth/Qwen3-8B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-8B-128K-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-f16",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q3-k-s",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q4-k-s",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q5-k-s",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q6-k",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q8-0",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-q8-k",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Instruct-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-8b-instruct-2512-f32",
      "model_name": "Ministral-3-8B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 32,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-f16",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q3-k-s",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q4-k-s",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q5-k-s",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q6-k",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q8-0",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-q8-k",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-8B-Reasoning-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-8b-reasoning-2512-f32",
      "model_name": "Ministral-3-8B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-8B-Reasoning-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 32,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-f16",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-BF16.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q3-k-s",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_S.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q4-k-s",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_S.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q5-k-s",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-Q5_K_S.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q6-k",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q8-0",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf"
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-q8-k",
      "model_name": "DeepSeek-R1-0528-Qwen3-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-f16",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-BF16.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q3-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-Q3_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q4-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-Q4_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q5-k-s",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-Q5_K_S.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
    },
    {
      "id": "deepseek-r1-distill-llama-8b-q8-k",
      "model_name": "DeepSeek-R1-Distill-Llama-8B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Llama-8B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-7b-f16",
      "model_name": "DeepSeek-R1-Distill-Qwen-7B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-7B-F16.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-7b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Qwen-7B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 6,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-7B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-7b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Qwen-7B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "8B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-f16",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-F16.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q3-k-s",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 2.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q4-k-s",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 3.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q5-k-s",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 4.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q6-k",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 5.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q8-0",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3n-e4b-it-q8-k",
      "model_name": "gemma-3n-E4B-it",
      "huggingface_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E4B-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-f16",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 14,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-BF16.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q3-k-s",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 2.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-Q3_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q4-k-s",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 3.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-Q4_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q5-k-s",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 4.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-Q5_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q6-k",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 5.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-Q6_K.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q8-0",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-Q8_0.gguf"
    },
    {
      "id": "granite-4-0-h-tiny-q8-k",
      "model_name": "granite-4.0-h-tiny",
      "huggingface_id": "unsloth/granite-4.0-h-tiny-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "7B",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 7,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-tiny-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-4b-f16",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-BF16.gguf"
    },
    {
      "id": "qwen3-vl-4b-q3-k-s",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-q4-k-s",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-q5-k-s",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-q6-k",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-4b-q8-0",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-4b-q8-k",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-4b-f32",
      "model_name": "Qwen3-VL-4B",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-f16",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-BF16.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q6-k",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q8-0",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-q8-k",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-f32",
      "model_name": "Qwen3-VL-4B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-f16",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-4b-instruct-1m-f32",
      "model_name": "Qwen3-VL-4B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-f16",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q3-k-s",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-4B-Thinking-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-4b-thinking-1m-f32",
      "model_name": "Qwen3-VL-4B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-4B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 16,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-f16",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-F16.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q3-k-s",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q4-k-s",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q5-k-s",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q6-k",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-Q6_K.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q8-0",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-Q8_0.gguf"
    },
    {
      "id": "qwen3-4b-instruct-2507-q8-k",
      "model_name": "Qwen3-4B-Instruct-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Instruct-2507-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-f16",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-F16.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q3-k-s",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q4-k-s",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q5-k-s",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q6-k",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-Q6_K.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q8-0",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-Q8_0.gguf"
    },
    {
      "id": "qwen3-4b-thinking-2507-q8-k",
      "model_name": "Qwen3-4B-Thinking-2507",
      "huggingface_id": "unsloth/Qwen3-4B-Thinking-2507-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Thinking-2507-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-4b-f16",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-BF16.gguf"
    },
    {
      "id": "qwen3-4b-q3-k-s",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-4b-q4-k-s",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-4b-q5-k-s",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-4b-q6-k",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Q6_K.gguf"
    },
    {
      "id": "qwen3-4b-q8-0",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-Q8_0.gguf"
    },
    {
      "id": "qwen3-4b-q8-k",
      "model_name": "Qwen3-4B",
      "huggingface_id": "unsloth/Qwen3-4B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-4b-128k-f16",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-BF16.gguf"
    },
    {
      "id": "qwen3-4b-128k-q3-k-s",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-4b-128k-q4-k-s",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-4b-128k-q5-k-s",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-4b-128k-q6-k",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-Q6_K.gguf"
    },
    {
      "id": "qwen3-4b-128k-q8-0",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-Q8_0.gguf"
    },
    {
      "id": "qwen3-4b-128k-q8-k",
      "model_name": "Qwen3-4B-128K",
      "huggingface_id": "unsloth/Qwen3-4B-128K-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-4B-128K-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-f16",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-BF16.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q3-k-s",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q4-k-s",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q5-k-s",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q6-k",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-Q6_K.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q8-0",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-Q8_0.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-q8-k",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-f32",
      "model_name": "gemma-3-4b-it-qat",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3-4b-it-f16",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-BF16.gguf"
    },
    {
      "id": "gemma-3-4b-it-q3-k-s",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-q4-k-s",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-q5-k-s",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-4b-it-q6-k",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3-4b-it-q8-0",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3-4b-it-q8-k",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-4b-it-f32",
      "model_name": "gemma-3-4b-it",
      "huggingface_id": "unsloth/gemma-3-4b-it-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-int4-f16",
      "model_name": "gemma-3-4b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-int4-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-int4-BF16.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-int4-q6-k",
      "model_name": "gemma-3-4b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-int4-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-int4-Q6_K.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-int4-q8-0",
      "model_name": "gemma-3-4b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-int4-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-4b-it-qat-int4-Q8_0.gguf"
    },
    {
      "id": "gemma-3-4b-it-qat-int4-f32",
      "model_name": "gemma-3-4b-it-qat-int4",
      "huggingface_id": "unsloth/gemma-3-4b-it-qat-int4-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 131072,
      "vram_requirements_gb": 16,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-f16",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-F16.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q3-k-s",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q4-k-s",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q5-k-s",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 2.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q6-k",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q8-0",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3n-e2b-it-q8-k",
      "model_name": "gemma-3n-E2B-it",
      "huggingface_id": "unsloth/gemma-3n-E2B-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3n-E2B-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "flux-2-klein-4b-q4-k-s",
      "model_name": "FLUX.2-klein-4B",
      "huggingface_id": "unsloth/FLUX.2-klein-4B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "4B",
      "default_context_size": 4096,
      "max_context_size": 4096,
      "vram_requirements_gb": 6,
      "capabilities": [
        "image_generation"
      ],
      "file_name": "flux-2-klein-4b-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-f16",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q3-k-s",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q4-k-s",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q5-k-s",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q6-k",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q8-0",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-q8-k",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Instruct-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-3b-instruct-2512-f32",
      "model_name": "Ministral-3-3B-Instruct-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Instruct-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-f16",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-BF16.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q3-k-s",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-Q3_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q4-k-s",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-Q4_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q5-k-s",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.9,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-Q5_K_S.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q6-k",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 2.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-Q6_K.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q8-0",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-Q8_0.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-q8-k",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Ministral-3-3B-Reasoning-2512-UD-Q8_K_XL.gguf"
    },
    {
      "id": "ministral-3-3b-reasoning-2512-f32",
      "model_name": "Ministral-3-3B-Reasoning-2512",
      "huggingface_id": "unsloth/Ministral-3-3B-Reasoning-2512-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "3B",
      "default_context_size": 8192,
      "max_context_size": 262144,
      "vram_requirements_gb": 12,
      "capabilities": [
        "chat"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-2b-f16",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-BF16.gguf"
    },
    {
      "id": "qwen3-vl-2b-q3-k-s",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-q4-k-s",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-q5-k-s",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-q6-k",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-2b-q8-0",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-2b-q8-k",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-2b-f32",
      "model_name": "Qwen3-VL-2B",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-f16",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-BF16.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q3-k-s",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q4-k-s",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q5-k-s",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q6-k",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q8-0",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-q8-k",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-f32",
      "model_name": "Qwen3-VL-2B-Thinking",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 262144,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-f16",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q3-k-s",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q4-k-s",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q5-k-s",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q6-k",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q8-0",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-q8-k",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Thinking-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-2b-thinking-1m-f32",
      "model_name": "Qwen3-VL-2B-Thinking-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Thinking-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-f16",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 4,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-BF16.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q3-k-s",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q4-k-s",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q5-k-s",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q6-k",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-Q6_K.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q8-0",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-Q8_0.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-q8-k",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 2,
      "capabilities": [
        "vision"
      ],
      "file_name": "Qwen3-VL-2B-Instruct-1M-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-vl-2b-instruct-1m-f32",
      "model_name": "Qwen3-VL-2B-Instruct-1M",
      "huggingface_id": "unsloth/Qwen3-VL-2B-Instruct-1M-GGUF",
      "quantization": "F32",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 1000000,
      "vram_requirements_gb": 8,
      "capabilities": [
        "vision"
      ],
      "file_name": "mmproj-F32.gguf"
    },
    {
      "id": "qwen3-1-7b-f16",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-BF16.gguf"
    },
    {
      "id": "qwen3-1-7b-q3-k-s",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-1-7b-q4-k-s",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 1,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-1-7b-q5-k-s",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 1.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-1-7b-q6-k",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-Q6_K.gguf"
    },
    {
      "id": "qwen3-1-7b-q8-0",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-Q8_0.gguf"
    },
    {
      "id": "qwen3-1-7b-q8-k",
      "model_name": "Qwen3-1.7B",
      "huggingface_id": "unsloth/Qwen3-1.7B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-1.7B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-1-5b-f16",
      "model_name": "DeepSeek-R1-Distill-Qwen-1.5B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 4,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-1-5b-q6-k",
      "model_name": "DeepSeek-R1-Distill-Qwen-1.5B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 1.5,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf"
    },
    {
      "id": "deepseek-r1-distill-qwen-1-5b-q8-0",
      "model_name": "DeepSeek-R1-Distill-Qwen-1.5B",
      "huggingface_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "2B",
      "default_context_size": 32768,
      "max_context_size": 131072,
      "vram_requirements_gb": 2,
      "capabilities": [
        "reasoning"
      ],
      "file_name": "DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf"
    },
    {
      "id": "gemma-3-1b-it-f16",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-BF16.gguf"
    },
    {
      "id": "gemma-3-1b-it-q3-k-s",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-1b-it-q4-k-s",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-1b-it-q5-k-s",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-1b-it-q6-k",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3-1b-it-q8-0",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 1,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3-1b-it-q8-k",
      "model_name": "gemma-3-1b-it",
      "huggingface_id": "unsloth/gemma-3-1b-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "1000M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 1,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-1b-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "qwen3-0-6b-f16",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 1.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-BF16.gguf"
    },
    {
      "id": "qwen3-0-6b-q3-k-s",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-Q3_K_S.gguf"
    },
    {
      "id": "qwen3-0-6b-q4-k-s",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-Q4_K_S.gguf"
    },
    {
      "id": "qwen3-0-6b-q5-k-s",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-Q5_K_S.gguf"
    },
    {
      "id": "qwen3-0-6b-q6-k",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.5,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-Q6_K.gguf"
    },
    {
      "id": "qwen3-0-6b-q8-0",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-Q8_0.gguf"
    },
    {
      "id": "qwen3-0-6b-q8-k",
      "model_name": "Qwen3-0.6B",
      "huggingface_id": "unsloth/Qwen3-0.6B-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "596M",
      "default_context_size": 32768,
      "max_context_size": 40960,
      "vram_requirements_gb": 0.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "Qwen3-0.6B-UD-Q8_K_XL.gguf"
    },
    {
      "id": "granite-4-0-350m-f16",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.8,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-BF16.gguf"
    },
    {
      "id": "granite-4-0-350m-q3-k-s",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-Q3_K_S.gguf"
    },
    {
      "id": "granite-4-0-350m-q4-k-s",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-Q4_K_S.gguf"
    },
    {
      "id": "granite-4-0-350m-q5-k-s",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-Q5_K_S.gguf"
    },
    {
      "id": "granite-4-0-350m-q6-k",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-Q6_K.gguf"
    },
    {
      "id": "granite-4-0-350m-q8-0",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-Q8_0.gguf"
    },
    {
      "id": "granite-4-0-350m-q8-k",
      "model_name": "granite-4.0-350m",
      "huggingface_id": "unsloth/granite-4.0-350m-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "352M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-350m-UD-Q8_K_XL.gguf"
    },
    {
      "id": "granite-4-0-h-350m-f16",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.7,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-BF16.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q3-k-s",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-Q3_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q4-k-s",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-Q4_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q5-k-s",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-Q5_K_S.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q6-k",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-Q6_K.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q8-0",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-Q8_0.gguf"
    },
    {
      "id": "granite-4-0-h-350m-q8-k",
      "model_name": "granite-4.0-h-350m",
      "huggingface_id": "unsloth/granite-4.0-h-350m-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "340M",
      "default_context_size": 8192,
      "max_context_size": 1048576,
      "vram_requirements_gb": 0.4,
      "capabilities": [
        "chat"
      ],
      "file_name": "granite-4.0-h-350m-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-270m-it-f16",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-F16.gguf"
    },
    {
      "id": "gemma-3-270m-it-q3-k-s",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.1,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-q4-k-s",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-q5-k-s",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-q6-k",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-Q6_K.gguf"
    },
    {
      "id": "gemma-3-270m-it-q8-0",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-Q8_0.gguf"
    },
    {
      "id": "gemma-3-270m-it-q8-k",
      "model_name": "gemma-3-270m-it",
      "huggingface_id": "unsloth/gemma-3-270m-it-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-UD-Q8_K_XL.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-f16",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "F16",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.6,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-F16.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q3-k-s",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q3_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.1,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-Q3_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q4-k-s",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q4_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-Q4_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q5-k-s",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q5_K_S",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.2,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-Q5_K_S.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q6-k",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q6_K",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-Q6_K.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q8-0",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q8_0",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-Q8_0.gguf"
    },
    {
      "id": "gemma-3-270m-it-qat-q8-k",
      "model_name": "gemma-3-270m-it-qat",
      "huggingface_id": "unsloth/gemma-3-270m-it-qat-GGUF",
      "quantization": "Q8_K",
      "family": "Dense",
      "parameters": "268M",
      "default_context_size": 8192,
      "max_context_size": 32768,
      "vram_requirements_gb": 0.3,
      "capabilities": [
        "chat"
      ],
      "file_name": "gemma-3-270m-it-qat-UD-Q8_K_XL.gguf"
    }
  ]
}
